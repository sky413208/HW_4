{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "語音辨識.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vnobt-lTVFU"
      },
      "source": [
        "import librosa\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import shutil\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aCkrtVHlyw4"
      },
      "source": [
        "def zip_list(file_path):\n",
        "    zf = zipfile.ZipFile(file_path, 'r')\n",
        "    zf.extractall()\n",
        "\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/voice_dataset.zip'\n",
        "zip_list(file_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tML8CTDrLQfo"
      },
      "source": [
        "OutputFolder = '/content/voice'\n",
        "# 新建檔案\n",
        "os.mkdir(OutputFolder)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cQbFC0aH5si"
      },
      "source": [
        "\n",
        "ImageList = os.listdir('/content/voice_dataset/train_set')\n",
        "ImageList.sort()\n",
        "ImageList.sort(key=lambda x:int(x[:-4]))\n",
        "#ImageList = [img for img in ImageList if len(img)>1]\n",
        "WordList = ['0','1','2','3','4','5','6','7']\n",
        "c = 0\n",
        "sr = pd.read_csv('/content/train.csv')\n",
        "\n",
        "word = (list(sr[\"label\"]))\n",
        "\n",
        "n = []\n",
        "for a in word :\n",
        "  n.append(str(a))\n",
        "  \n",
        "\n",
        "for w in WordList:\n",
        "  try:\n",
        "    os.chdir(OutputFolder) # 指定當前工作目錄\n",
        "    os.mkdir(w) # 創建字名資料夾\n",
        "    #MoveList = [img for img in ImageList if w in img]\n",
        "                \n",
        "  except: \n",
        "    os.chdir(OutputFolder) # 已有字名資料夾\n",
        "    #MoveList = [ img for img in ImageList if w in img ]\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# 移動所有影像檔到對應字名資料夾  \n",
        "for img in ImageList:\n",
        "   old_path = '/content/voice_dataset/train_set' + '/' + img\n",
        "   new_path = OutputFolder + '/' + n[c] + '/' + img\n",
        "   c += 1 \n",
        "   shutil.move(old_path, new_path)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e49bmpsRezca"
      },
      "source": [
        "DATA_PATH = \"/content/voice\"\n",
        "\n",
        "\n",
        "# Input: Folder Path\n",
        "# Output: Tuple (Label, Indices of the labels, one-hot encoded labels)\n",
        "def get_labels(path=DATA_PATH):\n",
        "    labels = os.listdir(path)\n",
        "    label_indices = np.arange(0, len(labels))\n",
        "    return labels, label_indices, tf.keras.utils.to_categorical(label_indices)\n",
        "\n",
        "\n",
        "# Handy function to convert wav2mfcc\n",
        "def wav2mfcc(file_path, max_len=11):\n",
        "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
        "    wave = wave[::3]\n",
        "    mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
        "\n",
        "    # If maximum length exceeds mfcc lengths then pad the remaining ones\n",
        "    if (max_len > mfcc.shape[1]):\n",
        "        pad_width = max_len - mfcc.shape[1]\n",
        "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "    # Else cutoff the remaining parts\n",
        "    else:\n",
        "        mfcc = mfcc[:, :max_len]\n",
        "    \n",
        "    return mfcc\n",
        "\n",
        "\n",
        "def save_data_to_array(path=DATA_PATH, max_len=11):\n",
        "    labels, _, _ = get_labels(path)\n",
        "    os.chdir('/content/voice')\n",
        "    for label in labels:\n",
        "        # Init mfcc vectors\n",
        "        mfcc_vectors = []\n",
        "\n",
        "        wavfiles = [path + '/' +label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
        "            mfcc = wav2mfcc(wavfile, max_len=max_len)\n",
        "            mfcc_vectors.append(mfcc)\n",
        "            os.chdir('/content')\n",
        "        np.save(label + '.npy', mfcc_vectors)\n",
        "        os.chdir('/content/voice')\n",
        "\n",
        "def get_train_test(split_ratio=0.6, random_state=42):\n",
        "    # Get available labels\n",
        "    os.chdir('/content')\n",
        "    labels, indices, _ = get_labels(DATA_PATH)\n",
        "\n",
        "    # Getting first arrays\n",
        "    X = np.load(labels[0] + '.npy')\n",
        "    y = np.zeros(X.shape[0])\n",
        "\n",
        "    # Append all of the dataset into one single array, same goes for y\n",
        "    for i, label in enumerate(labels[1:]):\n",
        "        x = np.load(label + '.npy')\n",
        "        X = np.vstack((X, x))\n",
        "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
        "\n",
        "    assert X.shape[0] == len(y)\n",
        "\n",
        "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
        "\n",
        "\n",
        "\n",
        "def prepare_dataset(path=DATA_PATH):\n",
        "  \n",
        "    labels, _, _ = get_labels(path)\n",
        "    data = {}\n",
        "    for label in labels:\n",
        "        data[label] = {}\n",
        "        data[label]['path'] = [path  + '/' +label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
        "\n",
        "        vectors = []\n",
        "\n",
        "        for wavfile in data[label]['path']:\n",
        "            wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
        "            # Downsampling\n",
        "            wave = wave[::3]\n",
        "            mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
        "            vectors.append(mfcc)\n",
        "\n",
        "        data[label]['mfcc'] = vectors\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def load_dataset(path=DATA_PATH):\n",
        "    data = prepare_dataset(path)\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    for key in data:\n",
        "        for mfcc in data[key]['mfcc']:\n",
        "            dataset.append((key, mfcc))\n",
        "\n",
        "    return dataset[:100]\n",
        "\n",
        "\n",
        "#print(prepare_dataset(DATA_PATH))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgtwQWyle-f_",
        "outputId": "75e0dc92-c1be-40d4-d347-7ffadd59e565"
      },
      "source": [
        "feature_dim_2 = 11\n",
        "save_data_to_array(max_len=feature_dim_2)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving vectors of label - '6': 100%|██████████| 109/109 [00:02<00:00, 50.57it/s]\n",
            "Saving vectors of label - '0': 100%|██████████| 111/111 [00:02<00:00, 49.97it/s]\n",
            "Saving vectors of label - '4': 100%|██████████| 106/106 [00:01<00:00, 56.44it/s]\n",
            "Saving vectors of label - '7': 100%|██████████| 105/105 [00:02<00:00, 44.70it/s]\n",
            "Saving vectors of label - '2': 100%|██████████| 113/113 [00:03<00:00, 28.32it/s]\n",
            "Saving vectors of label - '5': 100%|██████████| 156/156 [00:03<00:00, 49.02it/s]\n",
            "Saving vectors of label - '3': 100%|██████████| 103/103 [00:02<00:00, 50.61it/s]\n",
            "Saving vectors of label - '1': 100%|██████████| 126/126 [00:02<00:00, 48.92it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYFCsRoOiGL8"
      },
      "source": [
        "X_train, X_test, y_train, y_test = get_train_test()\n",
        "# # Feature dimension\n",
        "feature_dim_1 = 20\n",
        "channel = 1\n",
        "epochs = 50\n",
        "batch_size = 100\n",
        "verbose = 1\n",
        "num_classes = 8\n",
        "\n",
        "# Reshaping to perform 2D convolution\n",
        "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
        "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQaGsqPDTa-q"
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
        "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\n",
        "                  optimizer='Adam',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNka5cbfAHIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3df49b-26bc-4246-f8b4-4e40fdf4d679"
      },
      "source": [
        "model = get_model()\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 2s 183ms/step - loss: 5.0135 - accuracy: 0.1499 - val_loss: 2.0975 - val_accuracy: 0.1478\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.3788 - accuracy: 0.1586 - val_loss: 2.0940 - val_accuracy: 0.1935\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 2.1000 - accuracy: 0.1788 - val_loss: 2.0346 - val_accuracy: 0.2392\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.0417 - accuracy: 0.1906 - val_loss: 1.9992 - val_accuracy: 0.2500\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 2.0113 - accuracy: 0.2059 - val_loss: 1.9723 - val_accuracy: 0.2849\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.9980 - accuracy: 0.2215 - val_loss: 1.9414 - val_accuracy: 0.3199\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.9452 - accuracy: 0.2549 - val_loss: 1.8949 - val_accuracy: 0.3253\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.9313 - accuracy: 0.2595 - val_loss: 1.8525 - val_accuracy: 0.3522\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.8587 - accuracy: 0.3325 - val_loss: 1.8179 - val_accuracy: 0.3306\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.8560 - accuracy: 0.3299 - val_loss: 1.8024 - val_accuracy: 0.3548\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.7981 - accuracy: 0.3263 - val_loss: 1.7512 - val_accuracy: 0.3898\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.7128 - accuracy: 0.3847 - val_loss: 1.6981 - val_accuracy: 0.4167\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.6828 - accuracy: 0.3788 - val_loss: 1.6947 - val_accuracy: 0.3978\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.5821 - accuracy: 0.4201 - val_loss: 1.6718 - val_accuracy: 0.4167\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.5551 - accuracy: 0.4243 - val_loss: 1.6256 - val_accuracy: 0.4274\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 1.5252 - accuracy: 0.4529 - val_loss: 1.5791 - val_accuracy: 0.4462\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.4817 - accuracy: 0.4609 - val_loss: 1.5748 - val_accuracy: 0.4274\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.4065 - accuracy: 0.4938 - val_loss: 1.5535 - val_accuracy: 0.4677\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.3574 - accuracy: 0.5081 - val_loss: 1.5313 - val_accuracy: 0.4435\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 1.3198 - accuracy: 0.5375 - val_loss: 1.5202 - val_accuracy: 0.4355\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.2446 - accuracy: 0.5720 - val_loss: 1.5147 - val_accuracy: 0.4570\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 1.1904 - accuracy: 0.5659 - val_loss: 1.5458 - val_accuracy: 0.4489\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.0662 - accuracy: 0.6176 - val_loss: 1.4915 - val_accuracy: 0.4624\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 1.0573 - accuracy: 0.6432 - val_loss: 1.4941 - val_accuracy: 0.4570\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 1.0124 - accuracy: 0.6130 - val_loss: 1.5048 - val_accuracy: 0.4516\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.8910 - accuracy: 0.6849 - val_loss: 1.5040 - val_accuracy: 0.4677\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.8821 - accuracy: 0.6959 - val_loss: 1.5201 - val_accuracy: 0.4624\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.8757 - accuracy: 0.6704 - val_loss: 1.4967 - val_accuracy: 0.4839\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.7883 - accuracy: 0.7342 - val_loss: 1.5156 - val_accuracy: 0.4355\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.7631 - accuracy: 0.7255 - val_loss: 1.6774 - val_accuracy: 0.4301\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.7268 - accuracy: 0.7367 - val_loss: 1.6071 - val_accuracy: 0.4651\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.7669 - accuracy: 0.7258 - val_loss: 1.5788 - val_accuracy: 0.4624\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.6293 - accuracy: 0.7920 - val_loss: 1.5716 - val_accuracy: 0.4785\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.5893 - accuracy: 0.7893 - val_loss: 1.6483 - val_accuracy: 0.4570\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.6053 - accuracy: 0.8059 - val_loss: 1.6764 - val_accuracy: 0.4301\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.4907 - accuracy: 0.8264 - val_loss: 1.7766 - val_accuracy: 0.4516\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.4945 - accuracy: 0.8292 - val_loss: 1.7478 - val_accuracy: 0.4597\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 1s 98ms/step - loss: 0.4378 - accuracy: 0.8572 - val_loss: 1.7323 - val_accuracy: 0.4543\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.4568 - accuracy: 0.8399 - val_loss: 1.8992 - val_accuracy: 0.4704\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 1s 99ms/step - loss: 0.5062 - accuracy: 0.8195 - val_loss: 1.8334 - val_accuracy: 0.4328\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.4543 - accuracy: 0.8440 - val_loss: 1.8418 - val_accuracy: 0.4677\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.4024 - accuracy: 0.8597 - val_loss: 1.8375 - val_accuracy: 0.4758\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.3518 - accuracy: 0.8720 - val_loss: 1.8093 - val_accuracy: 0.4704\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.3346 - accuracy: 0.8884 - val_loss: 1.9897 - val_accuracy: 0.4489\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.3113 - accuracy: 0.8893 - val_loss: 1.9602 - val_accuracy: 0.4570\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.2825 - accuracy: 0.9052 - val_loss: 2.0263 - val_accuracy: 0.4543\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 1s 101ms/step - loss: 0.3025 - accuracy: 0.9052 - val_loss: 2.0577 - val_accuracy: 0.4409\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 1s 103ms/step - loss: 0.2618 - accuracy: 0.9250 - val_loss: 2.1446 - val_accuracy: 0.4274\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 1s 102ms/step - loss: 0.2657 - accuracy: 0.9081 - val_loss: 2.0847 - val_accuracy: 0.4677\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 1s 100ms/step - loss: 0.3040 - accuracy: 0.9064 - val_loss: 1.9912 - val_accuracy: 0.4489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcdcc39aa10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "460BryPLMLHn"
      },
      "source": [
        "def predict(filepath, model):\n",
        "    sample = wav2mfcc(filepath)\n",
        "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
        "    return get_labels()[0][\n",
        "            np.argmax(model.predict(sample_reshaped))\n",
        "    ]\n",
        "testdata = os.listdir('/content/voice_dataset/test_set')\n",
        "testdata.sort()\n",
        "testdata.sort(key=lambda x:int(x[:-4]))\n",
        "tt = pd.read_csv('//content/submission.csv')\n",
        "test_target = tt['label']\n",
        "test_predict = []\n",
        "\n",
        "\n",
        "\n",
        "for a in testdata:\n",
        "  test_predict.append(predict('/content/voice_dataset/test_set/' + a, model=model))\n",
        "\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wamtuoAOOG5m",
        "outputId": "a3896772-291c-4475-a61c-6a6c6691c633"
      },
      "source": [
        "from sklearn import metrics \n",
        "predict = []\n",
        "for a in test_predict:\n",
        "  predict.append(int(a))\n",
        "\n",
        "\n",
        "print(metrics.confusion_matrix(test_target, predict, labels=[0,1,2,3,4,5,6,7])) \n",
        "print(metrics.classification_report(test_target, predict)) "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 88 137  90 105  68 130 123  81]\n",
            " [  0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.11      0.19       822\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.11       822\n",
            "   macro avg       0.12      0.01      0.02       822\n",
            "weighted avg       1.00      0.11      0.19       822\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSweN_CISEjW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}